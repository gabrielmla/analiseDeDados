---
title: "Predição de Deputados Eleitos 2014"
author: "Gabriel Morais Lúcio de Araújo"
date: "28 de fevereiro de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(scales)
library(readr)
library(plotly)
library(caret)
library(rpart)
library(rpart.plot) 
```

```{r echo=FALSE}
eleicoes2014 <- read.csv("~/Documentos/Github/analiseDeDados/dados/eleicoes2014.filtrado.csv", encoding = "latin1")
trainK <- read.csv("~/Documentos/Github/analiseDeDados/lab_03/train.csv", encoding = "latin1")
trainK <- trainK %>% select(-nome, -numero_cadidato, -ID)
trainK[is.na(trainK)] <- 0
testK <- read.csv("~/Documentos/Github/analiseDeDados/lab_03/test.csv", encoding = "latin1")
testK <- testK %>% select(-nome, -numero_cadidato, -ID)
testK[is.na(testK)] <- 0
eleicoes2014[is.na(eleicoes2014)] <- 0
```

```{r}
## 75% of the sample size
smp_size <- floor(0.75 * nrow(eleicoes2014))

## set the seed to make your partition reproductible
set.seed(123)
train_ind <- sample(seq_len(nrow(eleicoes2014)), size = smp_size)

train <- eleicoes2014[train_ind, ]
test <- eleicoes2014[-train_ind, ]

## Kaggle
train.kaggle <- trainK
test.kaggle <- testK
```

### 1.Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador?

```{r}
train.kaggle.desbalanceamento.count <- train.kaggle %>%
  count(situacao_final)
train.kaggle.count.total <- train.kaggle %>%
  count()
nao_eleito.proportion <- 3719/4135
eleito.proportion <- 416/4135
```

Classe        | eleito       | nao_eleito  | Total
--------------|--------------|-------------|-------------
Instâncias    | 3719         | 416         | 4135
Proporção     | 0.1006       | 0.8993      | 1

Como podemos ver existe um desbalanceamento da classe situacao_final. Existem muito mais instâncias de **nao_eleito** do que de **eleito**, isso ira causar um desbalanceamento no classificador, que será mais tendencioso para **nao_eleito**. O classificador irá prever muito mais **nao_eleito**, poderiam ser utilizadas técnicas de balanceamento da clase. Por exemplo *Over Sampling*, onde serão inseridos dados da classe que possui menos instâncias.

### 2.Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo. 

```{r warning=FALSE}
train.kaggle$isDeputado <- ifelse(train.kaggle$descricao_ocupacao == 'DEPUTADO', 1, 0)
formula = as.formula(situacao_final ~ total_despesa + sexo + isDeputado + descricao_cor_raca + despesa_max_campanha)

modelo.glm <- train(formula,
                 data = train.kaggle,
                 method="glm",
                 family="binomial")

summary(modelo.glm)
```

Após executar o modelo glm, retirei as váriaveis que tinham graus de significância maior que **(0.001), deixando apenas as váriaveis mais significantes.

```{r}
#arvore1 <- train(formula,
                 data=treino,
                 method = "rpart",
                 cp=0.001,  # parâmetro de complexidade
                 maxdepth=20)

control <- rpart.control(maxdepth=20,
                         minsplit=20,
                         cp=0.001)
 
arvore2 <- rpart(formula, data=treino, control = control)

# Usando o rpart você pode visualizar a árvore
prp(arvore2)
```

```{r}
modelo <- train(formula,
                data=treino,
                method = "adaboost")

modelo.adaboost
```

### 3.Reporte acurácia, precision, recall e f-measure no treino e validação. Como você avalia os resultados? Justifique sua resposta.

```{r}

```

### 4.Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo.

```{r}

```

### 5.Envie seus melhores modelos à competição do Kaggle.

```{r}

```

